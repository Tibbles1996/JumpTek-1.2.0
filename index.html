<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>BlazePose Debug</title>
  <style>
    html, body { margin:0; padding:0; width:100vw; height:100vh; background:#111; }
    #container { position:relative; width:100vw; height:100vh; overflow:hidden; }
    #video, #canvas {
      position:absolute; top:0; left:0; width:100vw; height:100vh; object-fit:cover;
    }
    #canvas { z-index:2; pointer-events:none; background:transparent !important; }
    #video { z-index:1; }
    #status { position:absolute; top:10px; left:10px; z-index:10; 
      color:#fff; background:rgba(0,0,0,0.5); padding:4px 12px; border-radius:8px; }
  </style>
</head>
<body>
  <div id="container">
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
    <div id="status">Loading...</div>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core@4.19.0/dist/tf-core.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.19.0/dist/tf-backend-webgl.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter@4.19.0/dist/tf-converter.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection/dist/pose-detection.min.js"></script>
  <script>
    const statusDiv = document.getElementById('status');
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    let detector = null;

    function drawPose(pose) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      if (!pose || !pose.keypoints) return;
      ctx.save();
      ctx.lineWidth = 3;
      ctx.strokeStyle = "#0ff";
      ctx.fillStyle = "#ff0";
      // Draw keypoints (lowered threshold)
      for (const kp of pose.keypoints) {
        if (kp.score > 0.1) {
          ctx.beginPath();
          ctx.arc(
            kp.x * (canvas.width / video.videoWidth),
            kp.y * (canvas.height / video.videoHeight),
            6, 0, 2 * Math.PI
          );
          ctx.fill();
        }
      }
      // Draw skeleton
      const pairs = [
        [11,13],[13,15],[12,14],[14,16],[11,12],[12,24],[24,26],[26,28],[23,24],[23,25],[25,27],[27,29],[5,6],[6,8],[5,7],[7,9]
      ];
      ctx.strokeStyle = "#0ff";
      for (const [a,b] of pairs) {
        if (pose.keypoints[a] && pose.keypoints[b] &&
            pose.keypoints[a].score > 0.1 && pose.keypoints[b].score > 0.1) {
          ctx.beginPath();
          ctx.moveTo(
            pose.keypoints[a].x * (canvas.width / video.videoWidth),
            pose.keypoints[a].y * (canvas.height / video.videoHeight)
          );
          ctx.lineTo(
            pose.keypoints[b].x * (canvas.width / video.videoWidth),
            pose.keypoints[b].y * (canvas.height / video.videoHeight)
          );
          ctx.stroke();
        }
      }
      ctx.restore();
    }

    async function main() {
      statusDiv.textContent = "Requesting camera...";
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "user", width: { ideal: 640 }, height: { ideal: 480 } },
        audio: false
      });
      video.srcObject = stream;
      await new Promise(res => video.onloadedmetadata = res);

      function resizeCanvas() {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
      }
      resizeCanvas();
      window.addEventListener('resize', resizeCanvas);
      video.addEventListener('loadedmetadata', resizeCanvas);

      statusDiv.textContent = "Loading model...";
      await tf.setBackend('webgl');
      detector = await poseDetection.createDetector(
        poseDetection.SupportedModels.BlazePose,
        {runtime: 'tfjs', modelType: 'full'}
      );
      statusDiv.textContent = "Model loaded! Move in front of camera.";

      async function detectLoop() {
        if (video.readyState < 2) return requestAnimationFrame(detectLoop);

        if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
          resizeCanvas();
        }

        const poses = await detector.estimatePoses(video, {maxPoses: 1, flipHorizontal: true});
        console.log(poses);

        if (poses && poses.length > 0 && poses[0].keypoints.some(kp => kp.score > 0.1)) {
          drawPose(poses[0]);
          statusDiv.textContent = "Pose detected!";
        } else {
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          statusDiv.textContent = "No pose detected.";
        }
        requestAnimationFrame(detectLoop);
      }
      detectLoop();
    }

    main().catch(e => {
      statusDiv.textContent = "Error: " + e;
      console.error(e);
    });
  </script>
</body>
</html>
