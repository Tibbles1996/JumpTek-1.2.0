<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>MoveNet 3D Minimal Demo</title>
  <style>
    body, html { margin: 0; padding: 0; }
    #video, #canvas { position: absolute; top: 0; left: 0; }
    #status { position: absolute; top: 10px; left: 10px; color: #fff; background: rgba(0,0,0,0.5); padding: 4px 12px; border-radius: 8px; }
  </style>
</head>
<body>
  <video id="video" width="640" height="480" autoplay playsinline></video>
  <canvas id="canvas" width="640" height="480"></canvas>
  <div id="status">Loading...</div>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
  <script>
    const statusDiv = document.getElementById('status');
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');

    async function main() {
      statusDiv.textContent = "Requesting camera...";
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      await new Promise(res => video.onloadedmetadata = res);

      statusDiv.textContent = "Loading model...";
      await tf.setBackend('webgl');
      await tf.ready();
      const detector = await poseDetection.createDetector(
        poseDetection.SupportedModels.MoveNet,
        { modelType: 'MultiPose.Lightning' }
      );
      statusDiv.textContent = "Model loaded! Move in front of camera.";

      function drawPose(pose) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        if (!pose || !pose.keypoints3D) return;
        for (const kp of pose.keypoints3D) {
          if (kp && kp.score > 0.01 && kp.x != null && kp.y != null) {
            ctx.beginPath();
            ctx.arc(kp.x * canvas.width, kp.y * canvas.height, 6, 0, 2 * Math.PI);
            ctx.fillStyle = "#ff0";
            ctx.fill();
          }
        }
      }

      async function detectLoop() {
        const poses = await detector.estimatePoses(video, { maxPoses: 1, flipHorizontal: false });
        console.log(poses);
        if (poses.length > 0 && poses[0].keypoints3D && poses[0].keypoints3D.some(kp => kp.score > 0.01)) {
          drawPose(poses[0]);
          statusDiv.textContent = "3D Pose detected!";
        } else {
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          statusDiv.textContent = "No pose detected.";
        }
        requestAnimationFrame(detectLoop);
      }
      detectLoop();
    }

    main().catch(e => {
      statusDiv.textContent = "Error: " + e;
      console.error(e);
    });
  </script>
</body>
</html>
